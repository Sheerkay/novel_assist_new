# e:\Vs_Project\Novel_asisit\backend\app\services\ai_service.py
import requests
import json
import re
from flask import current_app
from ..prompts.prompt_manager import get_prompt, get_system_prompt
from ..utils.logger import ai_logger, log_ai_call
from .context_manager import ContextManager

def call_deepseek_api(messages, temperature=0.7, max_tokens=4000):
    api_key = current_app.config.get('DEEPSEEK_API_KEY')
    if not api_key:
        raise ValueError("DEEPSEEK_API_KEY æœªåœ¨é…ç½®ä¸­è®¾ç½®")

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek-chat",
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens
    }
    
    try:
        response = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"DeepSeek APIè°ƒç”¨é”™è¯¯: {e}")
        if e.response is not None:
            print(f"æ”¶åˆ°çš„é”™è¯¯å“åº” (çŠ¶æ€ç  {e.response.status_code}): {e.response.text}")
        else:
            print("æ— æ³•è¿æ¥åˆ°DeepSeek APIæœåŠ¡å™¨ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€é˜²ç«å¢™æˆ–ä»£ç†è®¾ç½®ã€‚")
        return None

def process_chapter_with_ai(chapter_content, user_prompt):
    prompt_template = get_prompt('process_chapter')
    if not prompt_template:
        return "é”™è¯¯ï¼šæ— æ³•åŠ è½½å¤„ç†ç« èŠ‚çš„æç¤ºè¯æ¨¡æ¿ã€‚"
    prompt = prompt_template.format(chapter_content=chapter_content[:3000], user_prompt=user_prompt)
    system_prompt = get_system_prompt('process_chapter_system')
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    response = call_deepseek_api(messages, temperature=0.7, max_tokens=4000)
    if response and 'choices' in response and len(response['choices']) > 0: return response['choices'][0]['message']['content']
    return None

def generate_chapter_summary(chapter_content):
    prompt_template = get_prompt('summarize_chapter')
    if not prompt_template:
        return "é”™è¯¯ï¼šæ— æ³•åŠ è½½ç”Ÿæˆç« èŠ‚æ‘˜è¦çš„æç¤ºè¯æ¨¡æ¿ã€‚"
    prompt = prompt_template.format(chapter_content=chapter_content[:4000])
    system_prompt = get_system_prompt('summarize_chapter_system')
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    
    # ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
    log_ai_call(
        prompt_type='ç« èŠ‚æ¦‚æ‹¬',
        prompt=f"System: {system_prompt}\n\nUser: {prompt}"
    )
    
    response = call_deepseek_api(messages, temperature=0.3, max_tokens=1500)
    
    if response and 'choices' in response and len(response['choices']) > 0:
        result = response['choices'][0]['message']['content']
        log_ai_call(
            prompt_type='ç« èŠ‚æ¦‚æ‹¬',
            prompt='',
            response=result
        )
        return result
    
    log_ai_call(
        prompt_type='ç« èŠ‚æ¦‚æ‹¬',
        prompt='',
        error='DeepSeek APIè°ƒç”¨å¤±è´¥'
    )
    return None

def analyze_chapter_characters(chapter_content):
    prompt_template = get_prompt('analyze_characters')
    if not prompt_template:
        return [{"name": "é”™è¯¯", "description": "æ— æ³•åŠ è½½åˆ†æäººç‰©çš„æç¤ºè¯æ¨¡æ¿ã€‚", "actions": []}]
    prompt = prompt_template.format(chapter_content=chapter_content[:4000])
    system_prompt = get_system_prompt('analyze_characters_system')
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    response = call_deepseek_api(messages, temperature=0.3, max_tokens=2000)
    if response and 'choices' in response and len(response['choices']) > 0:
        try:
            content = response['choices'][0]['message']['content']
            # æ›´ç¨³å¥åœ°æå–JSON
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```|(\[[\s\S]*\])', content)
            if json_match:
                json_str = json_match.group(1) or json_match.group(2)
                return json.loads(json_str)
        except json.JSONDecodeError as e: print(f"JSONè§£æé”™è¯¯: {e}")
    return [{"name": "æœªçŸ¥äººç‰©", "description": "äººç‰©åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•", "actions": ["æ— æ³•è·å–è¡ŒåŠ¨ä¿¡æ¯"]}]

def analyze_prompt_for_chapters(prompt):
    # æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°çš„promptç»“æ„æ¯”è¾ƒç®€å•ï¼Œç”¨æˆ·è¾“å…¥ç›´æ¥ä½œä¸ºå†…å®¹ï¼Œåªæœ‰ä¸€ä¸ªå›ºå®šçš„ç³»ç»Ÿæç¤ºã€‚
    # ä¹Ÿå¯ä»¥è€ƒè™‘å°† "ä½ æ˜¯ä¸€ä¸ª..." è¿™éƒ¨åˆ†ä¹Ÿæ¨¡æ¿åŒ–ï¼Œä½†ç›®å‰ä¿æŒåŸæ ·ä»¥æ±‚ç®€æ´ã€‚
    system_prompt = get_system_prompt('predict_chapters_system')
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
    response = call_deepseek_api(messages, temperature=0.3, max_tokens=100)
    if response and 'choices' in response and len(response['choices']) > 0:
        try:
            content = response['choices'][0]['message']['content']
            chapter_count = re.search(r'(\d+)\s*ä¸ªç« èŠ‚', content)
            if chapter_count: return int(chapter_count.group(1))
            else: return 10
        except (json.JSONDecodeError, ValueError) as e: print(f"è§£æç« èŠ‚æ•°é‡é”™è¯¯: {e}")
    return 10

def generate_content_with_intent(intent, user_prompt, context_manager):
    """
    æ ¹æ®æ„å›¾ç”Ÿæˆå†…å®¹ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰
    :param intent: æ„å›¾ç±»å‹
    :param user_prompt: ç”¨æˆ·æç¤ºè¯
    :param context_manager: ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
    :return: ç”Ÿæˆçš„å†…å®¹
    """
    # æ ¹æ®æ„å›¾é€‰æ‹©å¯¹åº”çš„æ¨¡æ¿å’Œç³»ç»Ÿæç¤ºè¯
    intent_config = {
        'plot_design': {
            'template': 'plot_design',
            'system': 'plot_design_system',
            'temperature': 0.5
        },
        'novel_generation': {
            'template': 'novel_generation',
            'system': 'novel_generation_system',
            'temperature': 0.7
        },
        'default': {
            'template': 'general_content',
            'system': 'generate_novel_system',
            'temperature': 0.7
        }
    }
    
    config = intent_config.get(intent, intent_config['default'])
    
    # è®°å½•ä½¿ç”¨çš„é…ç½®
    ai_logger.info(f'ğŸ¯ ä½¿ç”¨é…ç½®: æ„å›¾={intent}, æ¨¡æ¿={config["template"]}, ç³»ç»Ÿæç¤º={config["system"]}, æ¸©åº¦={config["temperature"]}')
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ„å»ºæ¶ˆæ¯
    messages = context_manager.build_messages(
        intent=intent,
        user_prompt=user_prompt,
        system_prompt_name=config['system'],
        template_name=config['template']
    )
    
    # è®°å½•æ„å»ºçš„æ¶ˆæ¯
    ai_logger.info(f'ğŸ“¨ æ„å»ºäº† {len(messages)} æ¡æ¶ˆæ¯')
    for i, msg in enumerate(messages):
        role = msg.get('role', 'unknown')
        content_preview = msg.get('content', '')[:200]
        ai_logger.info(f'  æ¶ˆæ¯{i+1} [{role}]: {content_preview}...')
    
    # è®°å½•AIè°ƒç”¨
    full_prompt = '\n\n'.join([f"[{msg['role']}]\n{msg['content']}" for msg in messages])
    log_ai_call(
        prompt_type=f'å†…å®¹ç”Ÿæˆ-{intent}',
        prompt=full_prompt
    )
    
    ai_logger.info(f'ğŸš€ è°ƒç”¨DeepSeek API (æ¸©åº¦={config["temperature"]}, æœ€å¤§tokens=4000)')
    response = call_deepseek_api(messages, temperature=config['temperature'], max_tokens=4000)
    
    if response and 'choices' in response and len(response['choices']) > 0:
        result = response['choices'][0]['message']['content']
        ai_logger.info(f'âœ… APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦')
        
        # è®°å½•å“åº”
        log_ai_call(
            prompt_type=f'å†…å®¹ç”Ÿæˆ-{intent}',
            prompt='',
            response=result
        )
        
        return result
    
    ai_logger.error('âŒ APIè°ƒç”¨å¤±è´¥æˆ–è¿”å›ä¸ºç©º')
    log_ai_call(
        prompt_type=f'å†…å®¹ç”Ÿæˆ-{intent}',
        prompt='',
        error='APIå“åº”ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®'
    )
    
    return "AIå“åº”ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚"

# ä¿ç•™æ—§çš„å‡½æ•°ä»¥ä¿æŒå‘åå…¼å®¹
def generate_novel_content(prompt, context, context_chapters):
    """ä½¿ç”¨AIç”Ÿæˆå†…å®¹ï¼ˆé€šç”¨å…¥å£ï¼Œé€‚ç”¨äºæœªæ˜ç¡®åˆ†ç±»çš„è¯·æ±‚ï¼‰"""
    return _generate_content_with_template('general_content', 'generate_novel_system', 
                                          prompt, context, context_chapters, temperature=0.7)

def generate_plot_design(prompt, context, context_chapters):
    """ç”Ÿæˆå‰§æƒ…è®¾è®¡æ–¹æ¡ˆ"""
    return _generate_content_with_template('plot_design', 'plot_design_system', 
                                          prompt, context, context_chapters, temperature=0.5)

def generate_full_novel(prompt, context, context_chapters):
    """ç”Ÿæˆå®Œæ•´å°è¯´ç« èŠ‚"""
    return _generate_content_with_template('novel_generation', 'novel_generation_system', 
                                          prompt, context, context_chapters, temperature=0.7)

def _generate_content_with_template(template_name, system_name, prompt, context, context_chapters, temperature=0.7):
    """å†…éƒ¨å‡½æ•°ï¼šä½¿ç”¨æŒ‡å®šæ¨¡æ¿ç”Ÿæˆå†…å®¹"""
    
    context_chapter_list = "\n".join([f"- ç« èŠ‚ {c.get('number', 'N/A')}: {c.get('title', 'æ— æ ‡é¢˜')}" for c in context_chapters])
    
    prompt_template = get_prompt(template_name)
    if not prompt_template:
        return f"é”™è¯¯ï¼šæ— æ³•åŠ è½½{template_name}æç¤ºè¯æ¨¡æ¿ã€‚"
        
    final_prompt = prompt_template.format(
        context=context,
        context_chapter_list=context_chapter_list,
        prompt=prompt
    )
    
    system_prompt = get_system_prompt(system_name)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": final_prompt}
    ]
    
    response = call_deepseek_api(messages, temperature=temperature, max_tokens=4000)
    
    if response and 'choices' in response and len(response['choices']) > 0:
        return response['choices'][0]['message']['content']
    
    return "AIå“åº”ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚"

def classify_user_intent(user_input):
    """åˆ¤æ–­ç”¨æˆ·è¾“å…¥çš„å…·ä½“æ„å›¾ç±»å‹"""
    system_prompt = get_system_prompt('classify_intent_system')
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ]
    
    ai_logger.info(f'ğŸ” å¼€å§‹åˆ†ç±»ç”¨æˆ·æ„å›¾ï¼Œè¾“å…¥é•¿åº¦: {len(user_input)} å­—ç¬¦')
    ai_logger.info(f'ğŸ“ è¾“å…¥å‰100å­—: {user_input[:100]}...')
    
    response = call_deepseek_api(messages, temperature=0.1, max_tokens=20)
    
    if response and 'choices' in response and len(response['choices']) > 0:
        intent = response['choices'][0]['message']['content'].strip().lower()
        ai_logger.info(f'ğŸ¯ æ„å›¾åˆ†ç±»åŸå§‹ç»“æœ: "{intent}"')
        
        # è¿”å›å…·ä½“çš„æ„å›¾ç±»å‹
        if 'chat' in intent:
            ai_logger.info('ğŸ’¬ åˆ¤å®šä¸º: æ™®é€šå¯¹è¯')
            return 'chat'
        elif 'plot_design' in intent or 'design' in intent:
            ai_logger.info('ğŸ“ åˆ¤å®šä¸º: å‰§æƒ…è®¾è®¡')
            return 'plot_design'
        elif 'novel_generation' in intent or 'generation' in intent:
            ai_logger.info('âœï¸ åˆ¤å®šä¸º: å°è¯´ç”Ÿæˆ')
            return 'novel_generation'
    
    # é»˜è®¤è®¤ä¸ºæ˜¯å°è¯´ç”Ÿæˆ
    ai_logger.warning('âš ï¸ æ— æ³•æ˜ç¡®åˆ¤å®šæ„å›¾ï¼Œé»˜è®¤ä¸º: å°è¯´ç”Ÿæˆ')
    return 'novel_generation'

def general_chat(user_input):
    """å¤„ç†æ™®é€šå¯¹è¯"""
    system_prompt = get_system_prompt('general_chat_system')
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ]
    
    response = call_deepseek_api(messages, temperature=0.7, max_tokens=2000)
    
    if response and 'choices' in response and len(response['choices']) > 0:
        return response['choices'][0]['message']['content']
    
    return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚è¯·ç¨åå†è¯•ã€‚"
