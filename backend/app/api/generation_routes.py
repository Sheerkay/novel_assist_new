# e:\Vs_Project\Novel_asisit\backend\app\api\generation_routes.py
from flask import Blueprint, request, jsonify, current_app
import os
import uuid
import json
import time
import re
from app.core.chapters import split_chapters
from app.core.context import ContextManager
from app.services import ai_service
from app.utils.logger import api_logger, log_request, log_response, log_chapter_summary

bp = Blueprint('generation', __name__, url_prefix='/api')

@bp.route('/chapter-summary', methods=['POST'])
def get_chapter_summary():
    data = request.json
    file_id, chapter_index = data.get('file_id'), data.get('chapter_index')
    
    chapters_file = os.path.join(current_app.config['UPLOAD_FOLDER'], 'analysis', f"{file_id}_chapters.json")
    try:
        with open(chapters_file, 'r', encoding='utf-8') as f: chapters_info = json.load(f)
    except: return jsonify({'error': 'æ‰¾ä¸åˆ°ç« èŠ‚ä¿¡æ¯'}), 404
    
    if chapter_index >= len(chapters_info['chapters']): return jsonify({'error': 'ç« èŠ‚ç´¢å¼•è¶…å‡ºèŒƒå›´'}), 400
    
    chapter_content = chapters_info['chapters'][chapter_index].get('content', '')
    summary = ai_service.generate_chapter_summary(chapter_content)
    
    if summary: return jsonify({'summary': summary}), 200
    else: return jsonify({'error': 'ç”Ÿæˆå‰§æƒ…æ¦‚æ‹¬å¤±è´¥'}), 500

@bp.route('/chapter-characters', methods=['POST'])
def get_chapter_characters():
    data = request.json
    file_id, chapter_index = data.get('file_id'), data.get('chapter_index')
    
    chapters_file = os.path.join(current_app.config['UPLOAD_FOLDER'], 'analysis', f"{file_id}_chapters.json")
    try:
        with open(chapters_file, 'r', encoding='utf-8') as f: chapters_info = json.load(f)
    except: return jsonify({'error': 'æ‰¾ä¸åˆ°ç« èŠ‚ä¿¡æ¯'}), 404
    
    if chapter_index >= len(chapters_info['chapters']): return jsonify({'error': 'ç« èŠ‚ç´¢å¼•è¶…å‡ºèŒƒå›´'}), 400
    
    chapter_content = chapters_info['chapters'][chapter_index].get('content', '')
    characters = ai_service.analyze_chapter_characters(chapter_content)
    
    if characters: return jsonify({'characters': characters}), 200
    else: return jsonify({'error': 'åˆ†æäººç‰©å¤±è´¥'}), 500

@bp.route('/process-chapter', methods=['POST'])
def process_chapter():
    data = request.json
    file_id, chapter_index, prompt = data.get('file_id'), data.get('chapter_index'), data.get('prompt')
    if not prompt: return jsonify({'error': 'éœ€è¦è¾“å…¥æç¤ºè¯'}), 400
    
    chapters_file = os.path.join(current_app.config['UPLOAD_FOLDER'], 'analysis', f"{file_id}_chapters.json")
    try:
        with open(chapters_file, 'r', encoding='utf-8') as f: chapters_info = json.load(f)
    except: return jsonify({'error': 'æ‰¾ä¸åˆ°ç« èŠ‚ä¿¡æ¯'}), 404
    
    if chapter_index >= len(chapters_info['chapters']): return jsonify({'error': 'ç« èŠ‚ç´¢å¼•è¶…å‡ºèŒƒå›´'}), 400
    
    chapter_content = chapters_info['chapters'][chapter_index].get('content', '')
    result = ai_service.process_chapter_with_ai(chapter_content, prompt)
    
    if result: return jsonify({'result': result}), 200
    else: return jsonify({'error': 'å¤„ç†å¤±è´¥'}), 500

@bp.route('/summarize-chapters', methods=['POST'])
def summarize_chapters_route():
    data = request.json
    chapters = data.get('chapters')
    
    # ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
    log_request('/api/summarize-chapters', {
        'chapter_count': len(chapters) if chapters else 0,
        'chapters': [{'title': c.get('title'), 'length': len(c.get('content', ''))} for c in chapters] if chapters else []
    })
    
    if not chapters:
        api_logger.error('âŒ é”™è¯¯: æ²¡æœ‰æä¾›éœ€è¦æ¦‚æ‹¬çš„ç« èŠ‚')
        return jsonify({'error': 'æ²¡æœ‰æä¾›éœ€è¦æ¦‚æ‹¬çš„ç« èŠ‚'}), 400
    
    for i, chapter in enumerate(chapters):
        api_logger.info(f'ğŸ“– ç« èŠ‚ {i+1}: {chapter.get("title", "æœªå‘½å")} ({len(chapter.get("content", ""))} å­—ç¬¦)')

    full_summary = ""
    for i, chapter in enumerate(chapters):
        chapter_content = chapter.get('content', '')
        chapter_title = chapter.get('title', f'ç« èŠ‚ {i+1}')
        
        api_logger.info(f'ğŸ¤– æ­£åœ¨ä¸ºç¬¬ {i+1} ç« ç”Ÿæˆæ¦‚æ‹¬...')
        
        # è°ƒç”¨AIæœåŠ¡ç”Ÿæˆå•ç« æ¦‚æ‹¬
        single_summary = ai_service.generate_chapter_summary(chapter_content)
        
        if single_summary:
            log_chapter_summary(i+1, chapter_title, len(chapter_content), True, single_summary)
            # ä¸ºæ¯ä¸ªæ¦‚æ‹¬æ·»åŠ æ ‡é¢˜ï¼Œä½¿å…¶åœ¨UIä¸­æ›´æ¸…æ™°
            full_summary += f"## {chapter_title} - å‰§æƒ…æ¦‚æ‹¬\n{single_summary}\n\n"
        else:
            log_chapter_summary(i+1, chapter_title, len(chapter_content), False)
            # å¦‚æœæŸä¸€ç« èŠ‚å¤±è´¥ï¼Œå¯ä»¥è®°å½•æˆ–è·³è¿‡
            full_summary += f"## {chapter_title} - å‰§æƒ…æ¦‚æ‹¬\n[æœ¬ç« æ¦‚æ‹¬ç”Ÿæˆå¤±è´¥]\n\n"
            
    if not full_summary.strip():
        api_logger.error('âŒ æ‰€æœ‰ç« èŠ‚çš„å‰§æƒ…æ¦‚æ‹¬éƒ½ç”Ÿæˆå¤±è´¥')
        return jsonify({'error': 'æ‰€æœ‰ç« èŠ‚çš„å‰§æƒ…æ¦‚æ‹¬éƒ½ç”Ÿæˆå¤±è´¥'}), 500

    api_logger.info(f'âœ… å…¨éƒ¨ç« èŠ‚æ¦‚æ‹¬å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_summary)} å­—ç¬¦')
    log_response('/api/summarize-chapters', 200, {'summary_length': len(full_summary)})
    return jsonify({'summary': full_summary.strip()})


@bp.route('/generate-with-analysis', methods=['POST'])
def generate_with_analysis():
    data = request.json
    prompt = data.get('prompt')
    context_string = data.get('context_string', '') 
    
    # è®°å½•è¯·æ±‚ä¿¡æ¯
    log_request('/api/generate-with-analysis', {
        'prompt_length': len(prompt) if prompt else 0,
        'context_length': len(context_string),
        'has_file_id': bool(data.get('file_id'))
    })
    
    api_logger.info(f'ğŸ“ æ”¶åˆ°ç”Ÿæˆè¯·æ±‚')
    api_logger.info(f'ğŸ“„ æç¤ºè¯é•¿åº¦: {len(prompt) if prompt else 0} å­—ç¬¦')
    api_logger.info(f'ğŸ“¦ ä¸Šä¸‹æ–‡é•¿åº¦: {len(context_string)} å­—ç¬¦')
    api_logger.info(f'ğŸ’¬ æç¤ºè¯å‰100å­—: {prompt[:100] if prompt else "æ— "}...')
    
    if not prompt: 
        api_logger.error('âŒ é”™è¯¯: æ²¡æœ‰æä¾›æç¤ºè¯')
        return jsonify({'error': 'éœ€è¦è¾“å…¥æç¤ºè¯'}), 400

    # å…ˆåˆ¤æ–­ç”¨æˆ·æ„å›¾
    api_logger.info('ğŸ¤” æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾...')
    intent = ai_service.classify_user_intent(prompt)
    api_logger.info(f'âœ… æ„å›¾è¯†åˆ«ç»“æœ: {intent}')
    
    # å¦‚æœæ˜¯æ™®é€šå¯¹è¯ï¼Œç›´æ¥è¿”å›å¯¹è¯å†…å®¹
    if intent == 'chat':
        api_logger.info('ğŸ’¬ è¯†åˆ«ä¸ºæ™®é€šå¯¹è¯ï¼Œè°ƒç”¨é—²èŠåŠŸèƒ½')
        chat_response = ai_service.general_chat(prompt)
        api_logger.info(f'âœ… å¯¹è¯ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(chat_response)} å­—ç¬¦')
        log_response('/api/generate-with-analysis', 200, {'is_chat': True, 'response_length': len(chat_response)})
        return jsonify({
            'content': chat_response,
            'is_chat': True  # æ ‡è®°è¿™æ˜¯æ™®é€šå¯¹è¯
        }), 200

    # åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨å¹¶è®¾ç½®ä¸Šä¸‹æ–‡
    api_logger.info(f'ğŸ“š åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ (æ„å›¾: {intent})')
    context_manager = ContextManager()
    context_manager.set_additional_context(context_string, [])
    api_logger.info(f'ğŸ“ ä¸Šä¸‹æ–‡è®¾ç½®å®Œæˆ')
    
    # æ ¹æ®ä¸åŒçš„åˆ›ä½œæ„å›¾ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç”Ÿæˆå†…å®¹
    api_logger.info(f'ğŸ¤– å¼€å§‹ç”Ÿæˆå†…å®¹ (æ„å›¾: {intent})')
    content = ai_service.generate_content_with_intent(intent, prompt, context_manager)
    api_logger.info(f'âœ… å†…å®¹ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(content) if content else 0} å­—ç¬¦')
    
    if not content: return jsonify({'error': 'å†…å®¹ç”Ÿæˆå¤±è´¥'}), 500
    
    summarized_chapter_numbers = []
    meta_match = re.search(r'<META_CHAPTERS>(.*?)</META_CHAPTERS>', content, re.DOTALL)
    if meta_match:
        numbers_str = meta_match.group(1)
        content = content[:meta_match.start()].strip()
        try:
            summarized_chapter_numbers = [int(n.strip()) for n in numbers_str.split(',') if n.strip()]
        except ValueError: print(f"è­¦å‘Šï¼šæ— æ³•è§£æå…ƒæ•°æ®ä¸­çš„ç« èŠ‚ç¼–å·: {numbers_str}")

    chapter_count = ai_service.analyze_prompt_for_chapters(prompt)
    newly_split_chapters = split_chapters(content)
    
    result = { 'content': content, 'chapter_count': chapter_count, 'prompt': prompt, 'chapters': newly_split_chapters, 'summarized_chapter_numbers': summarized_chapter_numbers }
    
    file_id = data.get('file_id')
    upload_folder = current_app.config['UPLOAD_FOLDER']
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿½åŠ åˆ°å·²æœ‰æ–‡ä»¶
    should_append = False
    if file_id:
        chapters_file = os.path.join(upload_folder, 'analysis', f"{file_id}_chapters.json")
        if os.path.exists(chapters_file):
            try:
                with open(chapters_file, 'r', encoding='utf-8') as f: 
                    chapters_info = json.load(f)
                # åªæœ‰å½“æ–‡ä»¶æ˜¯ç”Ÿæˆæ–‡ä»¶æ—¶æ‰è¿½åŠ 
                if chapters_info.get('is_generated', False):
                    should_append = True
            except:
                pass
    
    if should_append:
        # è¿½åŠ åˆ°å·²æœ‰çš„ç”Ÿæˆæ–‡ä»¶
        try:
            novel_filename = chapters_info['filename']
            original_path_novel = os.path.join(upload_folder, 'novels', f"{file_id}{os.path.splitext(novel_filename)[1]}")
            original_path_generated = os.path.join(upload_folder, 'generated', f"{file_id}_{novel_filename}")

            original_path = original_path_novel if os.path.exists(original_path_novel) else original_path_generated

            with open(original_path, 'a', encoding='utf-8') as f: f.write(f"\n\n{content}")
            with open(original_path, 'r', encoding='utf-8') as f: full_content = f.read()
            
            final_chapters = split_chapters(full_content)
            chapters_info['chapters'] = final_chapters
            
            with open(chapters_file, 'w', encoding='utf-8') as f: json.dump(chapters_info, f, ensure_ascii=False, indent=2)
            
            result.update({ 'is_new': False, 'file_id': file_id, 'chapters': final_chapters })
        except FileNotFoundError:
             return jsonify({'error': f"æ‰¾ä¸åˆ°æ–‡ä»¶IDä¸º {file_id} çš„åˆ†ææ–‡ä»¶æˆ–åŸå§‹æ–‡ä»¶ã€‚"}), 404
    else:
        # åˆ›å»ºæ–°çš„ç”Ÿæˆæ–‡ä»¶ï¼ˆæ— è®ºæ˜¯å¦ä¼ å…¥äº†file_idï¼‰
        file_id = str(uuid.uuid4())
        filename = f"åˆ›ä½œ_{int(time.time())}.txt"
        filepath = os.path.join(upload_folder, 'generated', f"{file_id}_{filename}")
        with open(filepath, 'w', encoding='utf-8') as f: f.write(content)
        
        chapters_info = { "file_id": file_id, "filename": filename, "chapters": newly_split_chapters, "is_generated": True, "generation_prompt": prompt, "target_chapters": chapter_count }
        chapters_file = os.path.join(upload_folder, 'analysis', f"{file_id}_chapters.json")
        with open(chapters_file, 'w', encoding='utf-8') as f: json.dump(chapters_info, f, ensure_ascii=False, indent=2)
        
        result.update({ 'file_id': file_id, 'filename': filename, 'is_new': True })
    
    return jsonify(result), 200

@bp.route('/text-labels', methods=['GET', 'POST'])
def manage_text_labels():
    if request.method == 'GET':
        # è·å–å½“å‰æ–‡æœ¬æ ‡ç­¾é…ç½®
        try:
            from ..config.text_labels import get_all_text_labels
            labels = get_all_text_labels()
            return jsonify(labels)
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    else:
        # æ›´æ–°æ–‡æœ¬æ ‡ç­¾é…ç½®
        data = request.json
        new_labels = data.get('labels', {})
        
        # æ›´æ–°é…ç½®
        from ..config.text_labels import update_text_labels
        update_text_labels(new_labels)
        return jsonify({'message': 'æ–‡æœ¬æ ‡ç­¾æ›´æ–°æˆåŠŸ', 'labels': new_labels})

@bp.route('/generate', methods=['POST'])
def generate_content():
    data = request.json
    prompt = data.get('prompt')
    context = data.get('context', '')
    context_chapters = data.get('context_chapters', [])
    context_labels = data.get('context_labels', {}) # æ¥æ”¶å‰ç«¯ä¼ æ¥çš„æ ‡ç­¾

    # ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„æ ‡ç­¾æ„å»ºä¸Šä¸‹æ–‡
    chapters_label = context_labels.get('chapters', 'åŸæ–‡ç« èŠ‚')
    summaries_label = context_labels.get('summaries', 'å‰§æƒ…æ¢—æ¦‚')

    # è¿™é‡Œå¯ä»¥æ ¹æ®æ‚¨çš„é€»è¾‘ï¼Œå°†è¿™äº›æ ‡ç­¾ç”¨äºæ„å»ºæ›´ç²¾ç¡®çš„ä¸Šä¸‹æ–‡æè¿°
    # ä¾‹å¦‚: f"å‚è€ƒ {chapters_label} å’Œ {summaries_label}..."
    
    generated_text = ai_service.generate_novel_content(prompt, context, context_chapters)
    
    if generated_text:
        return jsonify({'generated_text': generated_text})
    else:
        return jsonify({'error': 'ç”Ÿæˆå†…å®¹å¤±è´¥'}), 500
